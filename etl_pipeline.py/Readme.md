# Databricks ETL Pipeline using PySpark

## ğŸ“Œ Project Overview
This project demonstrates a simple ETL (Extract, Transform, Load) pipeline built using PySpark.

The pipeline processes sample e-commerce sales data, performs revenue aggregation, and exports the final results into CSV format.

---

## ğŸ›  Technologies Used
- Python 3
- PySpark
- Git & GitHub
- VS Code
- Homebrew (Mac setup)

---

## ğŸ”„ ETL Steps

### 1ï¸âƒ£ Extract
Loaded sample e-commerce transaction data into a Spark DataFrame.

### 2ï¸âƒ£ Transform
- Created a new `revenue` column (price Ã— quantity)
- Aggregated total revenue by product category

### 3ï¸âƒ£ Load
Exported aggregated results to CSV format.

---

## ğŸ“Š Sample Output

Category-wise total revenue:
- Electronics: 4700
- Clothing: 820

---

## â–¶ï¸ How to Run

```bash
python3 etl_pipeline.py